{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"TrainMatrix.csv\",index_col = 0)\n",
    "print(train.shape)\n",
    "test = pd.read_csv(\"TestValues.csv\")\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = train.sample(5)\n",
    "mans = s.index\n",
    "supps = s.columns[0:5]\n",
    "train[train.index.isin(mans)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmans = test.sample(5).index\n",
    "test[test.index.isin(tmans)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find mean of each users ratings\n",
    "user_ratings_mean = np.mean(train, axis = 1)\n",
    "## From each row (User rating) subtract the mean of that user's ratings\n",
    "## Thus, items that have not been rated have a value of 0\n",
    "train_modified = train.apply(lambda x: x-x.mean(), axis = 1).fillna(0)\n",
    "\n",
    "train_modified[train_modified.index.isin(mans)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define the number of nearest neighbors that we want as our default\n",
    "## This number will change later in a certain implementation\n",
    "## But because we use the number 100 later, we're keeping it like this.\n",
    "k = 100\n",
    "\n",
    "## Initialize our nearest neighbors classes\n",
    "## Find the nearest based on the standardized matrix\n",
    "\n",
    "## Nearest neighbors using euclidean distance\n",
    "nnEuc = neighbors.NearestNeighbors(n_neighbors = k,\n",
    "                                   metric = 'euclidean').fit(train_modified)\n",
    "## Nearest neighbors using cosine distance\n",
    "nnCos = neighbors.NearestNeighbors(n_neighbors = k,\n",
    "                                   metric = 'cosine').fit(train_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transform the training matrix into a slightly more usable format for a future purpose\n",
    "knownRatings = train.stack().reset_index()\n",
    "knownRatings.columns = [\"Manufacturer_ID\",\"Supplier_ID\",\"Rating\"]\n",
    "## Find the ratings that we don't know\n",
    "## We're only using the test dataframe because \n",
    "## If we tried to find the value for ALL the datapoints/combinations\n",
    "## It would take far too long\n",
    "unknownRatings = test[['Manufacturer_ID',\"Supplier_ID\",\"Rating\"]]\n",
    "knownRatings[knownRatings['Manufacturer_ID'].isin(mans)].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknownRatings.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPredictedRatingEuc(row):\n",
    "    \n",
    "    ## Number of neighbors we care about\n",
    "    k = 10\n",
    "    ## Name of manufacturer we care about\n",
    "    manu = row['Manufacturer_ID']\n",
    "    ## Name of supplier we care about\n",
    "    supp = row['Supplier_ID']\n",
    "    \n",
    "    ## Find all the ratings given to that supplier\n",
    "    ratingsdf = knownRatings[knownRatings['Supplier_ID'] == supp]\n",
    "    lrd = len(ratingsdf)\n",
    "    ## We're just brute force choosing 100 neighbors. We will trim this down later.\n",
    "    ## There probably is a more dynamic way to do this other than choosing 100 neighbors and trimming it down.\n",
    "    ## But for our purposes, this is fine.\n",
    "    ## For slight efficiency purposes we've added a comparison to the length of the ratings dataframe.\n",
    "    ## This probably won't help too much, but just in case.\n",
    "    dists, neighbors = nnEuc.kneighbors([train_modified.loc[manu]], n_neighbors = min(100,lrd))\n",
    "    dists = dists[0]\n",
    "    \n",
    "    ## Neighbors just has the index right now. We want the Manufacturer_ID\n",
    "    neighbors = np.array(train_modified.index[neighbors][0])\n",
    "    \n",
    "    ## Trim the neighbors to only the closest ones that have rated what we're looking for\n",
    "    hasRated = np.isin(neighbors,\n",
    "                       ratingsdf['Manufacturer_ID'])\n",
    "        \n",
    "    ## Distances of closest neighbors\n",
    "    dists = dists[hasRated]\n",
    "    \n",
    "    ## Names of closest neighbors\n",
    "    neighbors = neighbors[hasRated]\n",
    "    neighbors = neighbors[dists>0]\n",
    "    neighbors = neighbors[:k]\n",
    "    \n",
    "    dists = dists[dists>0]\n",
    "    dists = dists[:k]\n",
    "    \n",
    "    ## We want bigger Euclidean distances to have less weight\n",
    "    ## And smaller distances to have more weight\n",
    "    exp = lambda x : (x)**-1\n",
    "    vfunc = np.vectorize(exp)\n",
    "    dists = vfunc(dists)\n",
    "    \n",
    "    ## The ratings the closest neighbors have given to your supplier\n",
    "    ratingsdf = ratingsdf[ratingsdf['Manufacturer_ID'].isin(neighbors)]\n",
    "    \n",
    "    ## Define a lambda function to get the rating that the neighbor has given the item\n",
    "    ## This helps speed up the process\n",
    "    \n",
    "    ## 0 comes from the first row value\n",
    "    ## 2 comes from the index of the \"Rating\" column\n",
    "    ratingFinder = lambda x : ratingsdf[ratingsdf['Manufacturer_ID']==x].iat[0,2]\n",
    "    \n",
    "    ## Vectorize this function so we can quickly apply it\n",
    "    vfunc=np.vectorize(ratingFinder)\n",
    "    \n",
    "    ## Get a vector of the ratings given\n",
    "    ratingsVector = vfunc(neighbors)\n",
    "    \n",
    "    ## This is our estimated rating using the weighted average method we spoke about\n",
    "    estimatedRating = np.divide(np.sum(np.multiply(dists,\n",
    "                                                   ratingsVector)),\n",
    "                                np.sum(dists))\n",
    "    \n",
    "    return estimatedRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPredictedRatingCos(row):\n",
    "    \n",
    "    ## Number of neighbors we care about\n",
    "    k = 10\n",
    "    ## Name of manufacturer we care about\n",
    "    manu = row['Manufacturer_ID']\n",
    "    ## Name of supplier we care about\n",
    "    supp = row['Supplier_ID']\n",
    "    \n",
    "    ## Find all the ratings given to that supplier\n",
    "    ratingsdf = knownRatings[knownRatings['Supplier_ID'] == supp]\n",
    "    lrd = len(ratingsdf)\n",
    "    ## We're just brute force choosing 100 neighbors. We will trim this down later.\n",
    "    ## There probably is a more dynamic way to do this other than choosing 100 neighbors and trimming it down.\n",
    "    ## But for our purposes, this is fine.\n",
    "    ## For slight efficiency purposes we've added a comparison to the length of the ratings dataframe.\n",
    "    ## This probably won't help too much, but just in case.\n",
    "    dists, neighbors = nnCos.kneighbors([train_modified.loc[manu]], n_neighbors = min(100,lrd))\n",
    "    dists = dists[0]\n",
    "    \n",
    "    ## Neighbors just has the index right now. We want the Manufacturer_ID\n",
    "    neighbors = np.array(train_modified.index[neighbors][0])\n",
    "    \n",
    "    ## Trim the neighbors to only the closest ones that have rated what we're looking for\n",
    "    hasRated = np.isin(neighbors,\n",
    "                       ratingsdf['Manufacturer_ID'])\n",
    "        \n",
    "    ## Distances of closest neighbors\n",
    "    dists = dists[hasRated]\n",
    "    dists = dists[:k]\n",
    "    ## Taking into account negative cosines\n",
    "    dists = dists+1\n",
    "    \n",
    "    ## Names of closest neighbors\n",
    "    neighbors = neighbors[hasRated]\n",
    "    neighbors = neighbors[:k]\n",
    "    \n",
    "    ## The ratings the closest neighbors have given to your supplier\n",
    "    ratingsdf = ratingsdf[ratingsdf['Manufacturer_ID'].isin(neighbors)]\n",
    "    \n",
    "    ## Define a lambda function to get the rating that the neighbor has given the item\n",
    "    ## This helps speed up the process\n",
    "    \n",
    "    ## 0 comes from the first row value\n",
    "    ## 2 comes from the index of the \"Rating\" column\n",
    "    ratingFinder = lambda x : ratingsdf[ratingsdf['Manufacturer_ID']==x].iat[0,2]\n",
    "    \n",
    "    ## Vectorize this function so we can quickly apply it\n",
    "    vfunc=np.vectorize(ratingFinder)\n",
    "    \n",
    "    ## Get a vector of the ratings given\n",
    "    ratingsVector = vfunc(neighbors)\n",
    "    \n",
    "    ## This is our estimated rating using the weighted average method we spoke about\n",
    "    estimatedRating = np.divide(np.sum(np.multiply(dists,\n",
    "                                                   ratingsVector)),\n",
    "                                np.sum(dists))\n",
    "    \n",
    "    return estimatedRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Utility function we define \n",
    "## to print out the sum, mean, and standard deviation\n",
    "## Of a column\n",
    "def printstats(df,col):\n",
    "    print(col)\n",
    "    print(\"SUM: \",df[col].sum(), \n",
    "          \"\\nMEAN: \",df[col].mean(), \n",
    "          \"\\nSTD: \",df[col].std())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Take a sample from our testing dataframe\n",
    "## We take a sample because we don't have the processing power\n",
    "## To test all of the test data simultaneously\n",
    "## But because we have a VERY LARGE sample size\n",
    "## We can use this data to extrapolate\n",
    "tempdf = unknownRatings.sample(1000)\n",
    "\n",
    "## Find the predicted rating using Euclidean distance\n",
    "tempdf['EucRating'] = tempdf.apply(getPredictedRatingEuc,axis=1)\n",
    "## Find the predicted rating using Cosine distance\n",
    "tempdf['CosRating'] = tempdf.apply(getPredictedRatingCos,axis=1)\n",
    "## Predict the mean rating of this supplier\n",
    "## In other words, given the training data we have\n",
    "## What is a average rating given to this supplier\n",
    "## We use this to compare performances of other methodologies\n",
    "tempdf['ItemMeanRating'] = tempdf['Supplier_ID'].apply(lambda x : train[x].mean())\n",
    "tempdf['UserMeanRating'] = tempdf['Manufacturer_ID'].apply(lambda x: train.mean(axis=1)[x])\n",
    "\n",
    "## To show what the data looks like right now\n",
    "tempdf.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## With this code, we're finding the squared difference of each rating methodology\n",
    "## From the actual rating given\n",
    "tempdf['EucDiff'] = (tempdf['Rating']-tempdf['EucRating'])**2\n",
    "tempdf['MeanDiff'] = (tempdf['Rating']-tempdf['ItemMeanRating'])**2\n",
    "tempdf['CosDiff'] = (tempdf['Rating']-tempdf['CosRating'])**2\n",
    "tempdf['UserDiff'] = (tempdf['Rating']-tempdf['UserMeanRating'])**2\n",
    "\n",
    "## Print out the statistics for each of the errors of each methodology\n",
    "printstats(tempdf,'EucDiff')\n",
    "printstats(tempdf,'CosDiff')\n",
    "printstats(tempdf,'MeanDiff')\n",
    "printstats(tempdf,'UserDiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "foo = tempdf.sample(10)\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(foo.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's test if on average, using Cosine Collaborative Filtering returns less error than just predicting the Mean Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = []\n",
    "ediffs = []\n",
    "cdiffs = []\n",
    "av = []\n",
    "co = []\n",
    "eu = []\n",
    "ur = []\n",
    "udiffs = []\n",
    "\n",
    "for i in range(100):\n",
    "    if i%10 == 0 or i>95:\n",
    "        print(i)\n",
    "    ## Take a sample from our testing dataframe\n",
    "    ## We take a sample because we don't have the processing power\n",
    "    ## To test all of the test data simultaneously\n",
    "    ## But because we have a large sample size\n",
    "    ## We can use this data to extrapolate\n",
    "    tempdf = unknownRatings.sample(100)\n",
    "\n",
    "    ## Find the predicted rating using Cosine distance\n",
    "    tempdf['CosRating'] = tempdf.apply(getPredictedRatingCos,axis=1)\n",
    "\n",
    "    ## Find the predicted rating using Cosine distance\n",
    "    tempdf['EucRating'] = tempdf.apply(getPredictedRatingEuc,axis=1)\n",
    "\n",
    "    ## Predict the mean rating of this supplier\n",
    "    ## In other words, given the training data we have\n",
    "    ## What is a average rating given to this supplier\n",
    "    tempdf['MeanRating'] = tempdf['Supplier_ID'].apply(lambda x : train[x].mean())\n",
    "    tempdf['UserRating'] = tempdf['Manufacturer_ID'].apply(lambda x : train.loc[x].mean())\n",
    "\n",
    "    tempdf['MeanDiff'] = (tempdf['Rating']-tempdf['MeanRating'])**2\n",
    "    tempdf['CosDiff'] = (tempdf['Rating']-tempdf['CosRating'])**2\n",
    "    tempdf['EucDiff'] = (tempdf['Rating']-tempdf['EucRating'])**2\n",
    "    tempdf['UserDiff'] = (tempdf['Rating']-tempdf['UserRating'])**2\n",
    "\n",
    "    ## Append the difference in RMSE to the array\n",
    "    ## If this number is positive, this means that the MSE using mean to predict\n",
    "    ## Is greater than the MSE of using cosine to predict\n",
    "    ## For this specific instance\n",
    "    \n",
    "    md = np.sqrt(tempdf['MeanDiff'].mean())\n",
    "    cd = np.sqrt(tempdf['CosDiff'].mean())\n",
    "    ed = np.sqrt(tempdf['EucDiff'].mean())\n",
    "    ud = np.sqrt(tempdf['UserDiff'].mean())\n",
    "    \n",
    "    av.append(md)\n",
    "    co.append(cd)\n",
    "    eu.append(ed)\n",
    "    ur.append(ud)\n",
    "    diffs.append(md-cd)\n",
    "    ediffs.append(md-ed)\n",
    "    cdiffs.append(cd-ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demo = test[test['Manufacturer_ID']=='M_2299517']\n",
    "demo['Predicted_Rating']=demo.apply(getPredictedRatingCos,axis=1)\n",
    "demo.sort_values('Predicted_Rating', ascending = False)[['Supplier_ID',\"Predicted_Rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphaLevel = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "## One way anova to test if the means of all three methods are the same\n",
    "F, p = stats.f_oneway(av, co, eu, ur)\n",
    "## Because P < 0.05 \n",
    "## We can say there's enough evidence to conclude \n",
    "## That the means of all these methods are not the same\n",
    "## Which means that the average RMSE of each of these methods differs\n",
    "\"P = \", p, \"IS P LESS THAN ALPHA?:\", p<alphaLevel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of above test\n",
    "\n",
    "We've proven that the average RMSE of the three methodologies is not the same (i.e. at least one differs from the other two). Now we need to find which ones differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ttest for equality of means between cosine and average item rating\n",
    "stats.ttest_ind(a=av, b=co).pvalue < alphaLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"P Value\",stats.ttest_ind(a=av, b=co).pvalue, \"t statistic\",stats.ttest_ind(a=av, b=co).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ttest for equality of means between average item rating and euclidean\n",
    "stats.ttest_ind(a=av, b=eu).pvalue < alphaLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"P Value\",stats.ttest_ind(a=av, b=eu).pvalue, \"t statistic\",stats.ttest_ind(a=av, b=eu).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ttest for equality of means between euclidean and cosine\n",
    "stats.ttest_ind(a=co, b=eu).pvalue < alphaLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"P Value\",stats.ttest_ind(a=co, b=eu).pvalue, \"t statistic\",stats.ttest_ind(a=co, b=eu).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ttest for equality of means between user mean and average item rating\n",
    "stats.ttest_ind(a=ur, b = av).pvalue < alphaLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"P Value\",stats.ttest_ind(a=ur, b=av).pvalue, \"t statistic\",stats.ttest_ind(a=ur, b=av).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ttest for equality of means between user mean and cosine\n",
    "stats.ttest_ind(a=ur, b = co).pvalue < alphaLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"P Value\",stats.ttest_ind(a=ur, b=co).pvalue, \"t statistic\",stats.ttest_ind(a=ur, b=co).statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ttest for equality of means between user mean and euclidean\n",
    "stats.ttest_ind(a=ur, b = eu).pvalue < alphaLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"P Value\",stats.ttest_ind(a=ur, b=eu).pvalue, \"t statistic\",stats.ttest_ind(a=ur, b=eu).statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So now we've proven that none of the average RMSEs of the methods are equal to each other. \n",
    "\n",
    "Now we can use basic statistics to find which method is the best. We do this by looking at the means of each method. The one with the lowest mean is the best method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x = [\"Euclidean\",\n",
    "                  \"Mean Item Rating\",\n",
    "                  \"Cosine\",\n",
    "                  \"Mean User Rating\"],\n",
    "             y = [np.mean(eu),\n",
    "                  np.mean(av),\n",
    "                  np.mean(co),\n",
    "                  np.mean(ur)],\n",
    "             linestyle = 'None',\n",
    "             yerr = [np.std(x)/np.sqrt(len(x)) for x in [eu,av,co,ur]],\n",
    "             marker='.',\n",
    "             capsize=3)\n",
    "\n",
    "plt.annotate(np.round(np.mean(co),3), (0.1,np.mean(co)))\n",
    "\n",
    "plt.annotate(np.round(np.mean(eu),3), (1.1,np.mean(eu)))\n",
    "\n",
    "plt.annotate(np.round(np.mean(av),3), (2.1,np.mean(av)))\n",
    "\n",
    "plt.annotate(np.round(np.mean(ur),3), (2.65,np.mean(ur)))\n",
    "\n",
    "plt.title(\"Average RMSE\")\n",
    "plt.xlabel(\"METHODS\")\n",
    "plt.ylabel(\"RMSE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
